# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 100

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  # logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  # logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


# Windows Performance Counters plugin.
# These are the recommended method of monitoring system metrics on windows,
# as the regular system plugins (inputs.cpu, inputs.mem, etc.) rely on WMI,
# which utilize more system resources.
#
# See more configuration examples at:
#   https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_perf_counters

[[inputs.win_perf_counters]]
  
  # change name parameter 
  # name_override = "Performance"

  # optional, define JSON-SCADA groups
  # new points will be created on JSON-SCADA with tag name and object address based on groups an field names
  # if not defined, group1 will be "name" (Measurement)
  # if not defined, group2 will be "host"~"objectname"
  [inputs.win_perf_counters.tags]
    group1 = "TelegrafPerf"
    group2 = "Stats"
    group3 = ""

  #[[inputs.win_perf_counters.object]]
  #  # Process metrics, in this case for IIS only
  #  ObjectName = "Process"
  #  Counters = ["% Processor Time","Private Bytes","Virtual Bytes","Working Set"]
  #  Instances = ["idle"]
  #  Measurement = "win_proc"

  [[inputs.win_perf_counters.object]]
    # Processor usage, alternative to native, reports on a per core.
    ObjectName = "Processor"
    Instances = ["_Total"]
    Counters = [
      "% Idle Time",
    ]
    Measurement = "win_cpu"
    # Set to true to include _Total instance when querying for all (*).
    IncludeTotal=true

  [[inputs.win_perf_counters.object]]
    # Disk times and queues
    ObjectName = "LogicalDisk"
    Instances = ["C:"]
    Counters = [
      "% Idle Time",
      "% Free Space",
      "Free Megabytes",
    ]
    Measurement = "win_disk"
    # Set to true to include _Total instance when querying for all (*).
    #IncludeTotal=false

  #[[inputs.win_perf_counters.object]]
  #  ObjectName = "PhysicalDisk"
  #  Instances = ["*"]
  #  Counters = [
  #    "Disk Read Bytes/sec",
  #    "Disk Write Bytes/sec",
  #    "Current Disk Queue Length",
  #    "Disk Reads/sec",
  #    "Disk Writes/sec",
  #    "% Disk Time",
  #    "% Disk Read Time",
  #    "% Disk Write Time",
  #  ]
  #  Measurement = "win_diskio"

  [[inputs.win_perf_counters.object]]
    ObjectName = "Network Interface"
    Instances = ["*"]
    Counters = [
      "Bytes Received/sec",
      "Bytes Sent/sec",
      "Packets Received/sec",
      "Packets Sent/sec",
      "Packets Received Discarded",
      "Packets Outbound Discarded",
      "Packets Received Errors",
      "Packets Outbound Errors",
    ]
    Measurement = "win_net"

  [[inputs.win_perf_counters.object]]
    ObjectName = "System"
    Counters = [
      "System Up Time",
    ]
    Instances = ["------"]
    Measurement = "win_system"
    # Set to true to include _Total instance when querying for all (*).
    #IncludeTotal=false

  [[inputs.win_perf_counters.object]]
    # Example query where the Instance portion must be removed to get data back,
    # such as from the Memory object.
    ObjectName = "Memory"
    Counters = [
      "Available Bytes",
    ]
    # Use 6 x - to remove the Instance bit from the query.
    Instances = ["------"]
    Measurement = "win_mem"
    # Set to true to include _Total instance when querying for all (*).
    #IncludeTotal=false

  #[[inputs.win_perf_counters.object]]
  #  # Example query where the Instance portion must be removed to get data back,
  #  # such as from the Paging File object.
  #  ObjectName = "Paging File"
  #  Counters = [
  #    "% Usage",
  #  ]
  #  Instances = ["_Total"]
  #  Measurement = "win_swap"


# Windows system plugins using WMI (disabled by default, using
# win_perf_counters over WMI is recommended)


# # Read metrics about cpu usage
# [[inputs.cpu]]
#   ## Whether to report per-cpu stats or not
#   percpu = true
#   ## Whether to report total system cpu stats or not
#   totalcpu = true
#   ## If true, collect raw CPU time metrics.
#   collect_cpu_time = false
#   ## If true, compute and report the sum of all non-idle CPU states.
#   report_active = false


# # Read metrics about disk usage by mount point
# [[inputs.disk]]
#   ## By default stats will be gathered for all mount points.
#   ## Set mount_points will restrict the stats to only the specified mount points.
#   # mount_points = ["/"]
#
#   ## Ignore mount points by filesystem type.
#   ignore_fs = ["tmpfs", "devtmpfs", "devfs", "overlay", "aufs", "squashfs"]


# # Read metrics about disk IO by device
# [[inputs.diskio]]
#   ## By default, telegraf will gather stats for all devices including
#   ## disk partitions.
#   ## Setting devices will restrict the stats to the specified devices.
#   # devices = ["sda", "sdb", "vd*"]
#   ## Uncomment the following line if you need disk serial numbers.
#   # skip_serial_number = false
#   #
#   ## On systems which support it, device metadata can be added in the form of
#   ## tags.
#   ## Currently only Linux is supported via udev properties. You can view
#   ## available properties for a device by running:
#   ## 'udevadm info -q property -n /dev/sda'
#   # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
#   #
#   ## Using the same metadata source as device_tags, you can also customize the
#   ## name of the device via templates.
#   ## The 'name_templates' parameter is a list of templates to try and apply to
#   ## the device. The template may contain variables in the form of '$PROPERTY' or
#   ## '${PROPERTY}'. The first template which does not contain any variables not
#   ## present for the device is used as the device name tag.
#   ## The typical use case is for LVM volumes, to get the VG/LV name instead of
#   ## the near-meaningless DM-0 name.
#   # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


# # Read metrics about memory usage
# [[inputs.mem]]
#   # no configuration


# # Read metrics about swap memory usage
# [[inputs.swap]]
#   # no configuration

[[inputs.mqtt_consumer]]
  # this willl be JSON-SCADA group1
  name_override = "TelegrafMQTT" 
  ## Broker URLs for the MQTT server or cluster.  To connect to multiple
  ## clusters or standalone servers, use a seperate plugin instance.
  ##   example: servers = ["tcp://localhost:1883"]
  ##            servers = ["ssl://localhost:1883"]
  ##            servers = ["ws://localhost:1883"]
  servers = ["tcp://test.mosquitto.org:1883"]

  ## Topics that will be subscribed to.
  topics = [
    "$SYS/broker/messages/#",
  ]
  data_format = "value"
  data_type = "integer"
  # convert topic to group2
  #topic_tag = "group2" 

[[inputs.mqtt_consumer]]
  # this willl be JSON-SCADA group1
  name_override = "TelegrafMQTT" 
  ## Broker URLs for the MQTT server or cluster.  To connect to multiple
  ## clusters or standalone servers, use a seperate plugin instance.
  ##   example: servers = ["tcp://localhost:1883"]
  ##            servers = ["ssl://localhost:1883"]
  ##            servers = ["ws://localhost:1883"]
  servers = ["tcp://test.mosquitto.org:1883"]

  ## Topics that will be subscribed to.
  topics = [
    "$SYS/broker/uptime",
    "$SYS/broker/version",
  ]
  data_format = "value"
  data_type = "string"
  # convert topic to group2
  #topic_tag = "group2" 

[[inputs.opcua]]
  ## Metric name
  name = "TelegrafOPC-UA"
  endpoint = "opc.tcp://opcua.demo-this.com:51210/UA/SampleServer"
  security_policy = "None"
  security_mode = "None"
  auth_method = "Anonymous"
  certificate = "" # "/etc/telegraf/cert.pem"
  
  [[inputs.opcua.group]]
    #name = "group1_name"
    namespace = "2"
    identifier_type = "i"
    default_tags = { group2 = "demo" }
    nodes = [
      {name="float_value", identifier="10853"},
      {name="string_value", identifier="10855"},
      {name="date_value", identifier="10856"},
      {name="byte_value", identifier="10846"}
      ]
#{name="date_value", identifier="10856"}, # date values doesn't work
#{name="array_of_double", identifier="10938"} # array values doesn't work

[[inputs.mongodb]]
  name_override = "_SysMongoDB"  
  ## An array of URLs of the form:
  ##   "mongodb://" [user ":" pass "@"] host [ ":" port]
  ## For example:
  ##   mongodb://user:auth_key@10.10.3.30:27017,
  ##   mongodb://10.10.3.33:18832,
  servers = ["mongodb://127.0.0.1:27017"]
  gather_cluster_status = false
  gather_perdb_stats = false
  gather_col_stats = false
  #gather_top_stat = false
  col_stats_dbs = ["json_scada"]
  
###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# USE THIS TO DEBUG MESSAGES
#[[outputs.file]]
#  ## Files to write to, "stdout" is a specially handled file.
#  files = ["stdout", "metrics.out"]
#  
#  data_format = "json"

# USE THIS TO SEND DATA TO JSON-SCADA VIA UDP
# Generic socket writer capable of handling multiple socket types.
[[outputs.socket_writer]]
  ## URL to connect to
  address = "udp://127.0.0.1:51920"

  ## Data format to generate.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "json"

